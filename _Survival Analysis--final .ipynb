{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Passanger Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:786/format:webp/1*GulVod9PCsNLAx8Wjf1kcA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display the image\n",
    "Image(url=\"https://miro.medium.com/v2/resize:fit:786/format:webp/1*GulVod9PCsNLAx8Wjf1kcA.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train = pd.read_csv(\"input/train.csv\")\n",
    "test = pd.read_csv(\"input/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing values:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Test missing values:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the datasets\n",
    "print(\"Train missing values:\\n\", train.isnull().sum())\n",
    "print(\"Test missing values:\\n\", test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for age with median age\n",
    "train['Age'].fillna(train['Age'].median(), inplace=True)\n",
    "test['Age'].fillna(test['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing values for fare with median fare\n",
    "test['Fare'].fillna(test['Fare'].median(), inplace=True)\n",
    "\n",
    "# Fill missing values for embarked with the mode (most frequent value)\n",
    "train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop the 'Cabin' column if it exists\n",
    "train.drop('Cabin', axis=1, inplace=True, errors='ignore')\n",
    "test.drop('Cabin', axis=1, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary features\n",
    "features_to_drop = ['Name', 'Ticket', 'SibSp', 'Parch']\n",
    "train.drop(features_to_drop, axis=1, inplace=True)\n",
    "test.drop(features_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "train['Sex'] = label_encoder.fit_transform(train['Sex'])\n",
    "test['Sex'] = label_encoder.transform(test['Sex'])\n",
    "\n",
    "train['Embarked'] = label_encoder.fit_transform(train['Embarked'])\n",
    "test['Embarked'] = label_encoder.transform(test['Embarked'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7988826815642458\n",
      "Random Forest Accuracy: 0.8212290502793296\n",
      "Gradient Boosting Accuracy: 0.8212290502793296\n",
      "SVM Accuracy: 0.5977653631284916\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "log_reg = LogisticRegression()\n",
    "rf_classifier = RandomForestClassifier()\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train models\n",
    "log_reg.fit(X_train, y_train)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Logistic Regression Accuracy:\", log_reg.score(X_val, y_val))\n",
    "print(\"Random Forest Accuracy:\", rf_classifier.score(X_val, y_val))\n",
    "print(\"Gradient Boosting Accuracy:\", gb_classifier.score(X_val, y_val))\n",
    "print(\"SVM Accuracy:\", svm_classifier.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  accuracies represent the performance of different machine learning models on a given dataset. description for each model's accuracy:\n",
    "\n",
    "Logistic Regression Accuracy: The logistic regression model achieved an accuracy of approximately 79.89%. Logistic regression is a linear model used for binary classification tasks. It calculates the probability that an instance belongs to a particular class and makes predictions based on a threshold.\n",
    "\n",
    "Random Forest Accuracy: The random forest model achieved an accuracy of approximately 83.80%. Random forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or the average prediction (regression) of the individual trees.\n",
    "\n",
    "Gradient Boosting Accuracy: The gradient boosting model achieved an accuracy of approximately 82.68%. Gradient boosting is another ensemble learning technique that builds a sequence of weak learners (typically decision trees) and combines their predictions to improve accuracy.\n",
    "\n",
    "Support Vector Machine (SVM) Accuracy: The SVM model achieved an accuracy of approximately 59.78%. SVM is a supervised learning algorithm used for classification tasks. It finds the hyperplane that best separates the classes in the feature space and maximizes the margin between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Parameters: {'C': 2.9235032785505792}\n",
      "Best Model Accuracy: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'C': uniform(loc=0, scale=4)  # Regularization parameter\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    scoring='accuracy',  # Scoring method\n",
    "    cv=5,  # Number of folds in cross-validation\n",
    "    verbose=1,  # Controls the verbosity: the higher, the more messages\n",
    "    n_jobs=-1  # Number of jobs to run in parallel\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Model Accuracy:\", best_model.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 1000),  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt'],  # Number of features to consider at every split\n",
    "    'max_depth': randint(5, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 20),  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 20),  # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    scoring='accuracy',  # Scoring method\n",
    "    cv=5,  # Number of folds in cross-validation\n",
    "    verbose=1,  # Controls the verbosity: the higher, the more messages\n",
    "    n_jobs=-1  # Number of jobs to run in parallel\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Model Accuracy:\", best_model.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 1000),  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': randint(3, 10),  # Maximum depth of the individual regression estimators\n",
    "    'min_samples_split': randint(2, 20),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 20),  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=GradientBoostingClassifier(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of parameter settings that are sampled\n",
    "    scoring='accuracy',  # Scoring method\n",
    "    cv=5,  # Number of folds in cross-validation\n",
    "    verbose=1,  # Controls the verbosity: the higher, the more messages\n",
    "    n_jobs=-1  # Number of jobs to run in parallel\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Model Accuracy:\", best_model.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter for SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-3, 1e3),  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with reduced n_iter\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Reduce the number of iterations\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Model Accuracy:\", best_model.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revert dropping the 'Name' column\n",
    "train = pd.read_csv(\"input/train.csv\")\n",
    "test = pd.read_csv(\"input/test.csv\")\n",
    "\n",
    "# Extract titles from names\n",
    "train['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Create a family size feature\n",
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "# Binning numerical variables like age and fare into categories\n",
    "train['AgeBin'] = pd.cut(train['Age'], bins=[0, 18, 35, 50, 65, 100], labels=['0-18', '19-35', '36-50', '51-65', '66-100'])\n",
    "test['AgeBin'] = pd.cut(test['Age'], bins=[0, 18, 35, 50, 65, 100], labels=['0-18', '19-35', '36-50', '51-65', '66-100'])\n",
    "\n",
    "train['FareBin'] = pd.qcut(train['Fare'], q=5, labels=False)\n",
    "test['FareBin'] = pd.qcut(test['Fare'], q=5, labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Define a function to create bar charts\n",
    "def bar_chart(feature):\n",
    "    survived = train[train['Survived'] == 1][feature].value_counts()\n",
    "    dead = train[train['Survived'] == 0][feature].value_counts()\n",
    "    df = pd.DataFrame([survived, dead])\n",
    "    df.index = ['Survived', 'Dead']\n",
    "    df.plot(kind='bar', stacked=True, figsize=(10, 5))\n",
    "    plt.title(f'Survival by {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Number of passengers')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize survival by sex\n",
    "bar_chart('Sex')\n",
    "\n",
    "# Visualize survival by passenger class\n",
    "bar_chart('Pclass')\n",
    "\n",
    "# Visualize survival by number of parents/children\n",
    "bar_chart('Parch')\n",
    "\n",
    "# Visualize survival by port of embarkation\n",
    "bar_chart('Embarked')\n",
    "\n",
    "# Visualize survival rate by different features\n",
    "sns.barplot(x='Sex', y='Survived', data=train)\n",
    "plt.title(\"Survival Rate by Sex\")\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(x='Pclass', y='Survived', data=train)\n",
    "plt.title(\"Survival Rate by Pclass\")\n",
    "plt.show()\n",
    "\n",
    "# More visualizations can be added for other features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize survival by age\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=train, x='Age', hue='Survived', kde=True, bins=20, palette='husl')\n",
    "plt.title('Survival by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend(['Dead', 'Survived'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize survival by fare\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=train, x='Fare', hue='Survived', kde=True, bins=20, palette='husl')\n",
    "plt.title('Survival by Fare')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend(['Dead', 'Survived'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Survival by Passenger Class and Sex:\n",
    "#This chart will show survival rates based on both passenger class and sex,\n",
    "#providing insights into potential differences in survival rates among different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize survival by passenger class and sex\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=train, x='Pclass', y='Survived', hue='Sex', palette='Set1')\n",
    "plt.title('Survival by Passenger Class and Sex')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.legend(title='Sex', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Survival by Embarked Port and Passenger Class:\n",
    "#This chart will display survival rates based on the port of embarkation and passenger class, \n",
    "#providing insights into potential differences in survival rates among passengers who embarked from different ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize survival by embarked port and passenger class\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=train, x='Embarked', y='Survived', hue='Pclass', palette='Set2')\n",
    "plt.title('Survival by Embarked Port and Passenger Class')\n",
    "plt.xlabel('Embarked Port')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.legend(title='Passenger Class', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize individual classifiers\n",
    "log_reg = LogisticRegression()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=1)\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', log_reg), ('rf', rf_classifier), ('gb', gb_classifier), ('svm', svm_classifier)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the voting classifier\n",
    "print(\"Voting Classifier Accuracy:\", voting_classifier.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_classifier, X, y, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the cross-validation was performed using 5 folds, where the dataset was split into 5 equal parts, and the model was trained and evaluated 5 times, each time using a different fold as the validation set and the remaining folds as the training set.\n",
    "\n",
    "Here's a breakdown of the  information:\n",
    "\n",
    "Cross-Validation Scores: The array [0.7150838, 0.80898876, 0.83707865, 0.80337079, 0.8258427] contains the accuracy scores obtained for each fold of the cross-validation process. Each score represents the accuracy of the model on the validation set for a particular fold.\n",
    "\n",
    "Mean CV Accuracy: The mean cross-validation accuracy, calculated by averaging the accuracy scores obtained across all folds. In this case, the mean cross-validation accuracy is approximately 0.7981, indicating the average accuracy of the model across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Use feature importance scores for feature selection\n",
    "feature_selection = SelectFromModel(rf_classifier)\n",
    "feature_selection.fit(X_train, y_train)\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_features = feature_selection.get_support(indices=True)\n",
    "\n",
    "# Select features\n",
    "X_train_selected = X_train.iloc[:, selected_features]\n",
    "X_val_selected = X_val.iloc[:, selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE for oversampling the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize and train a neural network model\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the neural network model\n",
    "print(\"Neural Network Accuracy:\", nn_classifier.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network accuracy value of 0.7150837988826816 represents the proportion of correctly predicted instances out of the total instances in the dataset, as determined by the trained neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit the RandomForestClassifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
